import os
import zipfile
from datetime import datetime
from pathlib import Path
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from .log_cleaner import LogCleaner


class CommandHandler:
    """å‘½ä»¤å¤„ç†å™¨"""

    def __init__(self, data_dir: Path, cleaner: "LogCleaner"):
        self.data_dir = data_dir
        self.cleaner = cleaner

    async def handle_status(self) -> str:
        """å¤„ç† status å‘½ä»¤"""
        stats = self.cleaner.get_stats()

        lines = [
            "ğŸ“Š æ—¥å¿—çŠ¶æ€",
            f"â”œâ”€ æ–‡ä»¶æ€»æ•°: {stats['total_files']}",
            f"â”œâ”€ æ€»å¤§å°: {stats['total_size_mb']} MB",
            f"â”œâ”€ å·²å‹ç¼©: {stats['compressed_count']} ä¸ª",
        ]

        if stats["oldest_file"]:
            lines.append(
                f"â”œâ”€ æœ€æ—©æ—¥å¿—: {stats['oldest_file'].strftime('%Y-%m-%d %H:%M')}"
            )
        if stats["newest_file"]:
            lines.append(
                f"â”œâ”€ æœ€æ–°æ—¥å¿—: {stats['newest_file'].strftime('%Y-%m-%d %H:%M')}"
            )

        lines.append("â””â”€ ç›®å½•ç»Ÿè®¡:")
        for dir_name, dir_stat in stats["directories"].items():
            size_mb = round(dir_stat["size"] / 1024 / 1024, 2)
            lines.append(f"   â”œâ”€ {dir_name}: {dir_stat['count']} ä¸ª, {size_mb} MB")

        return "\n".join(lines)

    async def handle_search(self, keyword: str, limit: int = 50) -> str:
        """å¤„ç† search å‘½ä»¤"""
        if not keyword:
            return "âŒ è¯·æä¾›æœç´¢å…³é”®è¯"

        results = []
        count = 0

        for log_file in self.data_dir.rglob("*.log"):
            if count >= limit:
                break
            try:
                with open(log_file, encoding="utf-8", errors="ignore") as f:
                    for line_num, line in enumerate(f, 1):
                        if keyword.lower() in line.lower():
                            rel_path = log_file.relative_to(self.data_dir)
                            results.append(
                                f"[{rel_path}:{line_num}] {line.strip()[:100]}"
                            )
                            count += 1
                            if count >= limit:
                                break
            except Exception:
                pass

        if not results:
            return f"ğŸ” æœªæ‰¾åˆ°åŒ…å« '{keyword}' çš„æ—¥å¿—"

        header = f"ğŸ” æœç´¢ '{keyword}' ç»“æœ (å…± {len(results)} æ¡):\n"
        return header + "\n".join(results[:20])  # æœ€å¤šæ˜¾ç¤º20æ¡

    async def handle_clean(self) -> str:
        """å¤„ç† clean å‘½ä»¤"""
        result = await self.cleaner.cleanup()

        freed_mb = round(result["freed_bytes"] / 1024 / 1024, 2)
        return (
            f"ğŸ§¹ æ¸…ç†å®Œæˆ\n"
            f"â”œâ”€ å‹ç¼©æ–‡ä»¶: {result['compressed']} ä¸ª\n"
            f"â”œâ”€ åˆ é™¤æ–‡ä»¶: {result['deleted']} ä¸ª\n"
            f"â””â”€ é‡Šæ”¾ç©ºé—´: {freed_mb} MB"
        )

    async def handle_export(self, days: int = 7) -> str:
        """å¤„ç† export å‘½ä»¤ï¼Œå¯¼å‡ºæœ€è¿‘Nå¤©æ—¥å¿—"""
        export_dir = self.data_dir / "exports"
        export_dir.mkdir(exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        zip_path = export_dir / f"logs_export_{timestamp}.zip"

        cutoff = datetime.now().timestamp() - (days * 86400)
        file_count = 0

        with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as zf:
            for log_file in self.data_dir.rglob("*"):
                if log_file.is_file() and "exports" not in str(log_file):
                    if log_file.suffix in [".log", ".gz"]:
                        try:
                            if log_file.stat().st_mtime >= cutoff:
                                arcname = log_file.relative_to(self.data_dir)
                                zf.write(log_file, arcname)
                                file_count += 1
                        except Exception:
                            pass

        size_mb = round(zip_path.stat().st_size / 1024 / 1024, 2)
        return (
            f"ğŸ“¦ å¯¼å‡ºå®Œæˆ\n"
            f"â”œâ”€ æ–‡ä»¶: {zip_path}\n"
            f"â”œâ”€ åŒ…å«: {file_count} ä¸ªæ—¥å¿—æ–‡ä»¶\n"
            f"â””â”€ å¤§å°: {size_mb} MB"
        )

    def handle_help(self) -> str:
        """å¤„ç† help å‘½ä»¤"""
        return (
            "ğŸ“‹ LogPlus å‘½ä»¤å¸®åŠ©\n"
            "â”œâ”€ /logplus status          æŸ¥çœ‹æ—¥å¿—çŠ¶æ€\n"
            "â”œâ”€ /logplus search <è¯>     æœç´¢æ—¥å¿—å…³é”®è¯\n"
            "â”œâ”€ /logplus clean           æ‰‹åŠ¨æ¸…ç†æ—§æ—¥å¿—\n"
            "â”œâ”€ /logplus export [å¤©]     å¯¼å‡ºæœ€è¿‘Nå¤©æ—¥å¿—(é»˜è®¤7å¤©)\n"
            "â”œâ”€ /logplus send all        å‘é€å…¨éƒ¨æ—¥å¿—æ–‡ä»¶\n"
            "â”œâ”€ /logplus send errors     å‘é€é”™è¯¯æ—¥å¿—æ–‡ä»¶\n"
            "â”œâ”€ /logplus send plugin <å> å‘é€æŒ‡å®šæ’ä»¶æ—¥å¿—\n"
            "â””â”€ /logplus help            æ˜¾ç¤ºæ­¤å¸®åŠ©"
        )

    async def handle_send(self, target: str = "") -> tuple[str, Path | None]:
        """å¤„ç† send å‘½ä»¤ï¼Œè¿”å›(æ¶ˆæ¯æ–‡æœ¬, zipæ–‡ä»¶è·¯å¾„)"""
        if not target:
            return "âŒ è¯·æŒ‡å®šå‘é€ç›®æ ‡: all / errors / plugin <æ’ä»¶å>", None

        export_dir = self.data_dir / "exports"
        export_dir.mkdir(exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        if target == "all":
            return await self._pack_all_logs(export_dir, timestamp)
        elif target == "errors":
            return await self._pack_error_logs(export_dir, timestamp)
        else:
            # å°è¯•ä½œä¸ºæ’ä»¶åå¤„ç†
            return await self._pack_plugin_logs(export_dir, timestamp, target)

    async def _pack_all_logs(
        self, export_dir: Path, timestamp: str
    ) -> tuple[str, Path | None]:
        """æ‰“åŒ…å…¨éƒ¨æ—¥å¿—"""
        zip_path = export_dir / f"all_logs_{timestamp}.zip"
        file_count = 0

        with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as zf:
            for log_file in self.data_dir.rglob("*"):
                if (
                    log_file.is_file()
                    and "exports" not in str(log_file)
                    and log_file.suffix in [".log", ".gz"]
                ):
                    try:
                        arcname = log_file.relative_to(self.data_dir)
                        zf.write(log_file, arcname)
                        file_count += 1
                    except Exception:
                        pass

        if file_count == 0:
            os.remove(zip_path)
            return "âŒ æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—æ–‡ä»¶", None

        size_mb = round(zip_path.stat().st_size / 1024 / 1024, 2)
        message = f"ğŸ“¦ å…¨éƒ¨æ—¥å¿—å·²æ‰“åŒ…\nâ”œâ”€ æ–‡ä»¶æ•°: {file_count}\nâ””â”€ å¤§å°: {size_mb} MB"
        return message, zip_path

    async def _pack_error_logs(
        self, export_dir: Path, timestamp: str
    ) -> tuple[str, Path | None]:
        """æ‰“åŒ…é”™è¯¯æ—¥å¿—"""
        zip_path = export_dir / f"error_logs_{timestamp}.zip"
        file_count = 0
        error_dir = self.data_dir / "errors"

        if not error_dir.exists():
            return "âŒ é”™è¯¯æ—¥å¿—ç›®å½•ä¸å­˜åœ¨", None

        with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as zf:
            for log_file in error_dir.rglob("*"):
                if log_file.is_file() and log_file.suffix in [".log", ".gz"]:
                    try:
                        arcname = log_file.relative_to(self.data_dir)
                        zf.write(log_file, arcname)
                        file_count += 1
                    except Exception:
                        pass

        if file_count == 0:
            os.remove(zip_path)
            return "âŒ æ²¡æœ‰æ‰¾åˆ°é”™è¯¯æ—¥å¿—æ–‡ä»¶", None

        size_mb = round(zip_path.stat().st_size / 1024 / 1024, 2)
        message = f"ğŸ“¦ é”™è¯¯æ—¥å¿—å·²æ‰“åŒ…\nâ”œâ”€ æ–‡ä»¶æ•°: {file_count}\nâ””â”€ å¤§å°: {size_mb} MB"
        return message, zip_path

    async def _pack_plugin_logs(
        self, export_dir: Path, timestamp: str, plugin_keyword: str
    ) -> tuple[str, Path | None]:
        """æ‰“åŒ…æŒ‡å®šæ’ä»¶æ—¥å¿—ï¼ˆæ”¯æŒå…³é”®è¯åŒ¹é…ï¼‰"""
        plugins_dir = self.data_dir / "plugins"

        if not plugins_dir.exists():
            return "âŒ æ’ä»¶æ—¥å¿—ç›®å½•ä¸å­˜åœ¨", None

        # æŸ¥æ‰¾åŒ¹é…çš„æ’ä»¶
        available_plugins = [d.name for d in plugins_dir.iterdir() if d.is_dir()]
        matched_plugins = [
            p for p in available_plugins if plugin_keyword.lower() in p.lower()
        ]

        if not matched_plugins:
            plugins_list = "\n".join(f"  - {p}" for p in available_plugins)
            return (
                f"âŒ æœªæ‰¾åˆ°åŒ¹é… '{plugin_keyword}' çš„æ’ä»¶\nå¯ç”¨æ’ä»¶:\n{plugins_list}",
                None,
            )

        if len(matched_plugins) > 1:
            plugins_list = "\n".join(f"  - {p}" for p in matched_plugins)
            return (
                f"âŒ æ‰¾åˆ°å¤šä¸ªåŒ¹é…çš„æ’ä»¶ï¼Œè¯·æ›´å…·ä½“:\n{plugins_list}",
                None,
            )

        # æ‰“åŒ…å”¯ä¸€åŒ¹é…çš„æ’ä»¶æ—¥å¿—
        plugin_name = matched_plugins[0]
        plugin_dir = plugins_dir / plugin_name
        zip_path = export_dir / f"plugin_{plugin_name}_{timestamp}.zip"
        file_count = 0

        with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as zf:
            for log_file in plugin_dir.rglob("*"):
                if log_file.is_file() and log_file.suffix in [".log", ".gz"]:
                    try:
                        arcname = log_file.relative_to(self.data_dir)
                        zf.write(log_file, arcname)
                        file_count += 1
                    except Exception:
                        pass

        if file_count == 0:
            os.remove(zip_path)
            return f"âŒ æ’ä»¶ '{plugin_name}' æ²¡æœ‰æ—¥å¿—æ–‡ä»¶", None

        size_mb = round(zip_path.stat().st_size / 1024 / 1024, 2)
        message = (
            f"ğŸ“¦ æ’ä»¶æ—¥å¿—å·²æ‰“åŒ…\n"
            f"â”œâ”€ æ’ä»¶: {plugin_name}\n"
            f"â”œâ”€ æ–‡ä»¶æ•°: {file_count}\n"
            f"â””â”€ å¤§å°: {size_mb} MB"
        )
        return message, zip_path
